['In contrast, in this work we are interested in the challenging situation of learning a sequence of tasks without access to any previous or future task data and restricted to a fixed model capacity, as also studied in|Kirkpatrick et al.|;|Mallya & Lazebnik ;. In this paper, we propose a novel method to reduce the interference of a sparse representation of a given neuron in order to improve its performance when learning new tasks.| Our contribution would in contrast, lead to our sparse representation becoming more powerful and less vulnerable to catastrophic interference. As a result of our proposed method, we propose a novel way to reduce the interference of a sparse representation of a given neuron in order to improve its performance when learning new tasks.| Our contribution would in contrast, lead to our sparse representation becoming more powerful and less vulnerable to catastrophic interference.']
